# DS-GA-1003-Machine-Learning

Here are my notes and solutions for **DS-GA-1003: Machine Learning**, summarizing lecture materials, homework solutions, and mathematical foundations taught by *He He*.  

The course covers both theoretical and practical aspects of statistical learning, optimization, and modern machine learning models.

---

## ðŸ“˜ Topics Covered

- **hw1:** Error Decomposition & Polynomial Regression  
- **hw2:** Gradient Descent & Regularization  
- **hw3:** SVMs & Kernel Methods  
- **hw4:** Probabilistic Models  
- **hw5:** SGD for Multiclass Linear SVM  
- **hw6:** Decision Trees and Boosting  
- **hw7:** Computation Graphs, Backpropagation, and Neural Networks  

---

## ðŸ§  Lecture Summary Notes

I summarized all lectures and concepts into a structured note, including:

- **Statistical Learning Theory:** decision theory, empirical risk minimization, excess risk decomposition  
- **Optimization Methods:** gradient descent, stochastic gradient descent, convergence theory  
- **Linear & Kernel Methods:** perceptron, SVM, KKT conditions, kernel trick  
- **Probabilistic and Bayesian Models:** MLE, MAP, and Bayesian regression  
- **Ensemble Methods:** bagging, random forests, and boosting (Adaboost, Gradient Boosting)  
- **Neural Networks:** representation learning, activation functions, and backpropagation  
- **Unsupervised Learning:** K-means, Gaussian Mixture Models, and EM algorithm  

---

## ðŸ“„ PDF Summary

ðŸ‘‰ [Read Full Notes (Google Drive)](https://drive.google.com/file/d/1nWBIm9Id8T6v2E4RMtj-H-FP0_MKqlmM/view?usp=sharing)

This document systematically organizes all lectures and derivations covered in class, including formulas, algorithms, and key intuitions for each topic.

---

## ðŸ§© Additional Reference

- [MIT Missing Semester â€“ Optimization & Version Control](https://missing.csail.mit.edu/)  
- [He Heâ€™s Course Materials â€“ NYU DS-GA-1003](https://cs.nyu.edu/~heh/)  

---

**Author:** Wenxin Zhang  
*NYU DS-GA-1003 Machine Learning | Fall 2021*
